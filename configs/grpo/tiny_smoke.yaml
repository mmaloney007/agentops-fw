config_version: "0.2.0"
config_preset: "tiny-smoke"
base_model: "hf-internal-testing/tiny-random-GPTNeoXForCausalLM"
tasks: "tasks/robust_eval_gold.jsonl"
out: ""
steps: 4
max_prompt_len: 128
max_new_tokens: 32
temperature: 0.0
top_p: 1.0
lr: 1.0e-4
weight_decay: 0.0
gradient_accumulation: 1
max_grad_norm: 1.0
lora_rank: 2
lora_alpha: 4
lora_dropout: 0.0
lora_targets: "query_key_value,dense"
load_in_4bit: false
torch_dtype: "float32"
eval_interval: 1
deterministic: true
force_json_fallback: true
lam_latency: 0.0
mu_cost: 0.0
gamma_stability: 0.0
seed: 123
repro: true
cache_dataset: false
cache_dir: "out/cache"
checkpoint_every: 0
resume_from: null
no_silent_defaults: true
expected_dataset_hash: null
allow_dataset_drift: false
