{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P1 eval & tables (approachable walkthrough)\n",
    "\n",
    "Use this notebook to:\n",
    "- Run a GRPO training/eval loop (defaults to a tiny HF test model + tiny tasks for quick smoke).\n",
    "- Summarize runs into paper-style tables (reward mean/CI, latency p95/p99, json-valid rate).\n",
    "- Swap in your paper configs (local Qwen/RL checkpoints, P1 task files) for real results.\n",
    "\n",
    "ðŸŽ¯ **How to adapt for your paper:**\n",
    "- Set `BASE_MODEL` to your local Qwen/RL adapter path (e.g., `./models/qwen3-4b-thinking-2507`).\n+    - Optionally add `RESUME_FROM` to load a checkpoint.\n",
    "- Set `TASKS` to your P1 eval suite (e.g., `tasks/fc_tasks.jsonl`).\n",
    "- Increase `STEPS`/`MAX_NEW_TOKENS` for real training; enable validation if desired.\n",
    "- To summarize an existing run, skip the training cell and point `RUN_DIR` to the run directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from agent_stable_slo.train.grpo_train_loop import GRPOTrainConfig, train_loop\n",
    "from scripts.summarize_logs import summarize_file\n",
    "\n",
    "# --- User-facing config (edit these) ---\n",
    "BASE_MODEL = \"hf-internal-testing/tiny-random-GPTNeoXForCausalLM\"   # swap to your local Qwen/RL checkpoint\n",
    "TASKS = \"tasks/tiny_smoke.jsonl\"                                   # swap to P1 eval suite, e.g., tasks/fc_tasks.jsonl\n",
    "RUN_DIR = Path(\"out/notebook_p1_smoke\")                            # where outputs go; point to an existing run to summarize only\n",
    "RESUME_FROM = None                                                  # optional: existing checkpoint/run dir to resume\n",
    "STEPS = 40                                                          # raise for real runs (e.g., 500+)\n",
    "MAX_NEW_TOKENS = 64                                                 # raise for real runs (e.g., 128-192)\n",
    "CACHE_DATASET = True                                                # keep True for reproducibility\n",
    "BLOCKLIST = \"\"                                                     # e.g., \"forbidden1,forbidden2\"; empty to disable\n",
    "VAL_TASKS = None                                                    # optional validation tasks file\n",
    "VAL_INTERVAL = 0                                                    # validate every N steps; 0 disables\n",
    "SEED = 1234                                                         # set for reproducibility\n",
    "\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Using model={BASE_MODEL}\\nTasks={TASKS}\\nOut={RUN_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run GRPO training (skip this cell if you only want to summarize an existing run) ---\n",
    "cfg = GRPOTrainConfig(\n",
    "    base_model=BASE_MODEL,\n",
    "    tasks=TASKS,\n",
    "    out=str(RUN_DIR),\n",
    "    steps=STEPS,\n",
    "    max_prompt_len=256,\n",
    "    max_new_tokens=MAX_NEW_TOKENS,\n",
    "    deterministic=True,\n",
    "    cache_dataset=CACHE_DATASET,\n",
    "    load_in_4bit=False,\n",
    "    gradient_accumulation=1,\n",
    "    lr=1e-4,\n",
    "    lora_rank=4,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.0,\n",
    "    lora_targets=\"query_key_value,dense\",\n",
    "    eval_interval=max(1, STEPS // 4),\n",
    "    torch_dtype=\"float32\",\n",
    "    cache_dir=\"out/cache\",\n",
    "    val_tasks=VAL_TASKS,\n",
    "    val_interval=VAL_INTERVAL,\n",
    "    blocklist=BLOCKLIST,\n",
    "    seed=SEED,\n",
    "    resume_from=RESUME_FROM,\n",
    ")\n",
    "\n",
    "train_loop(cfg)\n",
    "print(f\"Run complete: {RUN_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summarize into a paper-style table ---\n",
    "# Choose train_log.jsonl or eval.jsonl depending on what you ran\n",
    "log_path = RUN_DIR / \"train_log.jsonl\"  # swap to eval.jsonl if summarizing eval\n",
    "summary = summarize_file(log_path)\n",
    "df = pd.DataFrame([summary])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visuals: reward and latency over time (if train_log exists) ---\n",
    "import json\n",
    "import plotly.express as px\n",
    "\n",
    "records = []\n",
    "for line in log_path.read_text(encoding=\"utf-8\").splitlines():\n",
    "    if not line.strip():\n",
    "        continue\n",
    "    records.append(json.loads(line))\n",
    "df_log = pd.DataFrame(records)\n",
    "\n",
    "fig_reward = px.line(df_log, x=\"step\", y=\"reward\", title=\"Reward over steps\")\n",
    "fig_latency = px.line(df_log, x=\"step\", y=\"latency_ms\", title=\"Latency (ms) over steps\")\n",
    "fig_reward.show()\n",
    "fig_latency.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output (tiny smoke)\n",
    "\n",
    "| file                                |   json_valid_rate |   latency_p95_ms |   latency_p99_ms |   reward_ci_lower |   reward_ci_upper |   reward_mean |   ttft_avg_ms |\n",
    "|:------------------------------------|------------------:|-----------------:|-----------------:|------------------:|------------------:|--------------:|--------------:|\n",
    "| out/notebook_p1_smoke/train_log.jsonl |                 1 |            ~95   |            ~96   |                 2 |                 2 |             2 |        ~93    |\n",
    "\n",
    "Your table will reflect your model/tasks; for real runs, rewards/latencies will differ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swap in paper runs\n",
    "- Set `BASE_MODEL` to your local Qwen or RL-adapted checkpoint (or use `RESUME_FROM` to load a saved adapter).\n",
    "- Point `TASKS` at your P1 eval suite (e.g., `tasks/fc_tasks.jsonl`).\n",
    "- Increase `STEPS`/`MAX_NEW_TOKENS` and optionally enable validation (`VAL_TASKS`, `VAL_INTERVAL`).\n",
    "- To summarize an existing run, skip the training cell and set `RUN_DIR` to the run dir, then re-run the summary/visual cells."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
